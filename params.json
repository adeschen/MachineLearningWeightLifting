{"name":"Qualitative Activity Recognition of Barbell Lifting Exercises","tagline":"Machine Learning Project ","body":"\r\nThe use of devices such as Jawbone Up, Nike FuelBand, and Fitbit enable the collection of a large amount of data about personal activity. While this information is usually used to assess the quantity of activity done, it could be interesting to see if it could also be used to quantify the quality of the activity done. In this context, six participants have been asked to perform barbell lifts correctly and incorrectly in 5 different ways. The data from accelerometers on the belt, forearm, arm, and dumbell were gathered.\r\n\r\nThe goal of this project is to validate that, through the use of machine learning techniques, the manner in which people did the exercise can be predicted by using the accelerometers information.\r\nData Preprocessing\r\n\r\nThe training data for this project are available here:\r\n\r\nhttps://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv\r\n\r\nThe test data are available here:\r\n\r\nhttps://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv\r\n\r\nIn the data, the way the participants performed the barbell lifts has been classified into 5 categories:\r\n\r\n    A - Exactly according to the specification\r\n    B - Throwing the elbows to the front\r\n    C - Lifting the dumbbell only halfway\r\n    D - Lowering the dumbbell only halfway\r\n    E - Throwing the hips to the front\r\n\r\nThe “classe” variable is the one containing the category of the performed exercise. This is the outcome variable. All the other variables are potential predictors.\r\n\r\n```\r\n#### URl for training set\r\ntrainUrl <- \"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv\"\r\n#### Load training set\r\npml_training <- read.csv(url(trainUrl), row.names = 1)\r\n#### Number of variables\r\nnbrCol <- ncol(pml_training)\r\nnbrCol\r\n## [1] 159\r\n#### Number of observations\r\nnbrRow <- nrow(pml_training)\r\nnbrRow\r\n## [1] 19622\r\n```\r\n\r\nThe training dataset contains 159 variables (including the outcome variable). A total of 19622 observations are present.\r\n\r\n## Splitting the Training Dataset\r\n\r\nThe initial training dataset is split into a training and testing dataset to allow out-of-sample calculation. The training set will contain 65% of the data.\r\n\r\n```\r\n#### Upload needed package\r\nlibrary(caret)\r\n#### Set seed to enable reproducibility\r\nset.seed(1584)\r\n#### Split initial dataset in 2 partitions\r\ninTrain <- createDataPartition(y=pml_training$classe, p=0.65, list=FALSE)\r\n#### Create training dataset and testing dataset\r\ntraining <- pml_training[inTrain, ]\r\ntesting  <- pml_training[-inTrain, ]\r\n```\r\n\r\n### Data Cleaning\r\n\r\nFirst, some potential predictors have missing data. Missing data can take the form of a value or no value at all.\r\n\r\n```\r\n#### Calculate the ratio of missing values for each variable \r\nratio_missing_data <- apply(X = training, MARGIN = 2, \r\n    FUN= function(x) {sum(is.na(x) == TRUE | x == \"\" | x == \"#DIV/0!\")/sum(length(x))})\r\n#### Only retained the variables with missing values\r\nonly_missing_data <- subset(ratio_missing_data, ratio_missing_data > 0)\r\n#### See the range of the ratio of missing values for those variables\r\nmissingDataRange <- range(only_missing_data)\r\nmissingDataRange\r\n## [1] 0.9800894 1.0000000\r\n#### Number of variables with missing data\r\nnbreMissingData <- length(only_missing_data)\r\nnbreMissingData\r\n## [1] 100\r\n```\r\n\r\nThere are 100 variables with missing data. The ratio of missing data, for those predictors, is very high. In fact, the minimum ratio of missing data is 0.9800894.\r\n\r\nAll variables with missing data won’t be retained as predictors and are removed from the training dataset.\r\n\r\n```\r\n#### Select columns to retain in the dataset\r\ncolumn_to_keep <- !(colnames(training) %in% names(only_missing_data))\r\n#### New training dataset without variables with missing values\r\ntraining <- training[, colnames(training)[column_to_keep]]\r\n```\r\n\r\nThe first columns of the new training dataset contains variables which are not related to data gathered from accelerometers such time and date, name, etc… Those variables should also be removed from the training dataset.\r\n\r\n```\r\n#### A look at the first column names\r\ncolnames(training[,1:10])\r\n##  [1] \"user_name\"            \"raw_timestamp_part_1\" \"raw_timestamp_part_2\"\r\n##  [4] \"cvtd_timestamp\"       \"new_window\"           \"num_window\"          \r\n##  [7] \"roll_belt\"            \"pitch_belt\"           \"yaw_belt\"            \r\n## [10] \"total_accel_belt\"\r\n#### The first 6 variables are removed from the training dataset\r\ntraining <- training[ , -c(1:6)]\r\n#### Number of variables\r\nnbrCol <- ncol(training)\r\nnbrCol\r\n## [1] 53\r\n```\r\n\r\nThere is some highly correlated variables.\r\n\r\n```\r\n#### Upload needed package\r\nlibrary(corrplot)\r\n#### Calculate correlation between variable\r\ncorr.matrix <- cor(training[,-nbrCol])\r\n#### Show correlation\r\ncorrplot(corr.matrix ,method=\"square\", type=\"lower\", tl.cex=.55)\r\n```\r\n![Correlation Graph](https://raw.githubusercontent.com/adeschen/MachineLearningWeightLifting/master/images/corrGraph.png)\r\n\r\nDue to the high correlation of some variables and considering the large number of variables, a principal component pre-processing will be performed. The procedure will retain 95% of the variability of the original variables.\r\n\r\n```\r\n#### Principal component pre-processing\r\npreProc <- preProcess(training[, -nbrCol], method = \"pca\", thresh = 0.95)\r\n#### Transform training dataset using PCA result (the outcome is not used)\r\ntrainingPC <- predict(preProc, training[, -nbrCol])\r\n```\r\n\r\nThe processed dataset contains 25 predictors.\r\n\r\n## Method Selection\r\n\r\nThe random forest method has been selected since it is among the top performing algorithms. The random forest is also an appropriate model to perform classification of categorical outcomes.\r\nModel Training\r\n\r\nA k-fold cross validation will be used during the training step. This method involves splitting the dataset into k-subsets. In this case, the number of folds has been set to 4.\r\n\r\n```\r\n#### Set the number of subsets for the k-fold cross validation\r\nnumberOfCrossValidation <- 4\r\n#### The k-fold cross validation is set using \"cv\" option for method parameter\r\ntrainingControl <- trainControl(method = \"cv\", number = numberOfCrossValidation, \r\n                                    allowParallel = TRUE)\r\n#### Build a random forest model using k-fold cross validation\r\ntrainingModel <- train(training$classe ~ ., data=trainingPC, method=\"rf\", \r\n                        trControl = trainingControl)\r\ntrainingModel\r\n## Random Forest \r\n## \r\n## 12757 samples\r\n##    24 predictor\r\n##     5 classes: 'A', 'B', 'C', 'D', 'E' \r\n## \r\n## No pre-processing\r\n## Resampling: Cross-Validated (4 fold) \r\n## Summary of sample sizes: 9568, 9568, 9568, 9567 \r\n## Resampling results across tuning parameters:\r\n## \r\n##   mtry  Accuracy   Kappa      Accuracy SD  Kappa SD   \r\n##    2    0.9636278  0.9539771  0.001932411  0.002432382\r\n##   13    0.9572783  0.9459477  0.004400744  0.005556971\r\n##   25    0.9531237  0.9406966  0.004704790  0.005940001\r\n## \r\n## Accuracy was used to select the optimal model using  the largest value.\r\n## The final value used for the model was mtry = 2.\r\n\r\n#### See the result for each submodel\r\nplot(trainingModel)\r\n```\r\n![Training Model Graph](https://raw.githubusercontent.com/adeschen/MachineLearningWeightLifting/master/images/trainingModel.png)\r\n\r\nThe training method used accuracy to select the optimal model. The importance of each variable in the final model can be visualized.\r\n\r\n```\r\n#### Calculate the importance of each variable in the model\r\nmostImportantVar <- varImp(trainingModel, scale = FALSE)\r\nplot(mostImportantVar)\r\n```\r\n\r\n![Variable Importance Graph](https://raw.githubusercontent.com/adeschen/MachineLearningWeightLifting/master/images/variableImportance.png)\r\n\r\nUsing the final model, the confusion matrix and statistics are extracted from the training dataset.\r\n\r\n```\r\n#### Calculate the confusion matrix using predicted versus real results\r\nconf.matrix <- confusionMatrix(training$classe, \r\n                                predict(trainingModel, trainingPC))\r\nconf.matrix\r\n## Confusion Matrix and Statistics\r\n## \r\n##           Reference\r\n## Prediction    A    B    C    D    E\r\n##          A 3627    0    0    0    0\r\n##          B    0 2469    0    0    0\r\n##          C    0    0 2225    0    0\r\n##          D    0    0    0 2091    0\r\n##          E    0    0    0    0 2345\r\n## \r\n## Overall Statistics\r\n##                                      \r\n##                Accuracy : 1          \r\n##                  95% CI : (0.9997, 1)\r\n##     No Information Rate : 0.2843     \r\n##     P-Value [Acc > NIR] : < 2.2e-16  \r\n##                                      \r\n##                   Kappa : 1          \r\n##  Mcnemar's Test P-Value : NA         \r\n## \r\n## Statistics by Class:\r\n## \r\n##                      Class: A Class: B Class: C Class: D Class: E\r\n## Sensitivity            1.0000   1.0000   1.0000   1.0000   1.0000\r\n## Specificity            1.0000   1.0000   1.0000   1.0000   1.0000\r\n## Pos Pred Value         1.0000   1.0000   1.0000   1.0000   1.0000\r\n## Neg Pred Value         1.0000   1.0000   1.0000   1.0000   1.0000\r\n## Prevalence             0.2843   0.1935   0.1744   0.1639   0.1838\r\n## Detection Rate         0.2843   0.1935   0.1744   0.1639   0.1838\r\n## Detection Prevalence   0.2843   0.1935   0.1744   0.1639   0.1838\r\n## Balanced Accuracy      1.0000   1.0000   1.0000   1.0000   1.0000\r\n```\r\n\r\nBased on the accuracy results from the confusion matrix on the training data, the accuracy is 100%.\r\n\r\n\r\n## Out-of-sample Estimation\r\n\r\nThe testing test is used to estimate the out of sample error. The same cleaning steps must be applied to the testing dataset.\r\n\r\n```\r\n#### New testing dataset without variables with missing values\r\ntesting <- testing[, colnames(testing)[column_to_keep]]\r\n#### The first 6 variables are removed from the testing dataset\r\ntesting <- testing[ , -c(1:6)]\r\n#### Transform testing using PCA result\r\ntestingPC <- predict(preProc, testing[, -nbrCol])\r\n```\r\n\r\nUsing the obtained model, the confusion matrix and statistics are extracted from the testing dataset.\r\n\r\n```\r\n#### Calculate the confusion matrix on the testing dataset\r\nconf.matrix <- confusionMatrix(testing$classe, \r\n                               predict(trainingModel, testingPC))\r\nconf.matrix\r\n## Confusion Matrix and Statistics\r\n## \r\n##           Reference\r\n## Prediction    A    B    C    D    E\r\n##          A 1927   10   13    1    2\r\n##          B   21 1293   14    0    0\r\n##          C    3   12 1172    9    1\r\n##          D    1    0   36 1084    4\r\n##          E    0    9   11    9 1233\r\n## \r\n## Overall Statistics\r\n##                                           \r\n##                Accuracy : 0.9773          \r\n##                  95% CI : (0.9735, 0.9807)\r\n##     No Information Rate : 0.2843          \r\n##     P-Value [Acc > NIR] : < 2.2e-16       \r\n##                                           \r\n##                   Kappa : 0.9713          \r\n##  Mcnemar's Test P-Value : NA              \r\n## \r\n## Statistics by Class:\r\n## \r\n##                      Class: A Class: B Class: C Class: D Class: E\r\n## Sensitivity            0.9872   0.9766   0.9406   0.9828   0.9944\r\n## Specificity            0.9947   0.9937   0.9956   0.9929   0.9948\r\n## Pos Pred Value         0.9867   0.9736   0.9791   0.9636   0.9770\r\n## Neg Pred Value         0.9949   0.9944   0.9869   0.9967   0.9988\r\n## Prevalence             0.2843   0.1929   0.1815   0.1607   0.1806\r\n## Detection Rate         0.2807   0.1883   0.1707   0.1579   0.1796\r\n## Detection Prevalence   0.2845   0.1934   0.1744   0.1639   0.1838\r\n## Balanced Accuracy      0.9910   0.9851   0.9681   0.9878   0.9946\r\n```\r\n\r\nBased on the accuracy results from the confusion matrix on the training data, the accuracy is expected to be 97.73% and the out-of-sample error rate is expected to be 2.27%.\r\n\r\n\r\n## Prediction of 20 test cases\r\n\r\nThe model is used to predict 20 test cases.\r\n\r\n```\r\n#### URL for test cases\r\ntestingCasesURL <- \"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv\"\r\n#### Load test cases\r\ntestingCases <- read.csv(url(testingCasesURL), row.names = 1)\r\n#### Prepare test cases by keeping only pertinent variables\r\ntestingCases <- testingCases[, colnames(testingCases) %in% colnames(training)]\r\n#### Transform test cases using PCA result\r\ntestingCasesPC <- predict(preProc, testingCases)\r\n#### Predict classes using the model\r\npredictedValues <- predict(trainingModel, testingCasesPC)\r\n#### View predictions\r\npredictedValues\r\n##  [1] B A C A A E D B A A A C B A E E A B B B\r\n## Levels: A B C D E\r\n```\r\n\r\n## References\r\n\r\nThe data for this project come from this source: http://groupware.les.inf.puc-rio.br/har.\r\n\r\nUgulino, W.; Cardador, D.; Vega, K.; Velloso, E.; Milidiu, R.; Fuks, H. Wearable Computing: Accelerometers’ Data Classification of Body Postures and Movements. Proceedings of 21st Brazilian Symposium on Artificial Intelligence. Advances in Artificial Intelligence - SBIA 2012. In: Lecture Notes in Computer Science. , pp. 52-61. Curitiba, PR: Springer Berlin / Heidelberg, 2012. ISBN 978-3-642-34458-9. DOI: 10.1007/978-3-642-34459-6_6.\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}